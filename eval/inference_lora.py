#!/usr/bin/env python3
"""
CAD-Recode LoRAæ¨ç†è„šæœ¬
æ”¯æŒåŠ è½½LoRAæƒé‡è¿›è¡Œç‚¹äº‘åˆ°ä»£ç çš„æ¨ç†


ä½¿ç”¨æ–¹æ³•:
python inference_lora.py --base_model Qwen/Qwen3-1.7B-Base --lora_path checkpoints_qwen3_lora --point_cloud_file data/val/point_cloud_cache/0.npy"""

import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
import argparse
import numpy as np
import torch
from pathlib import Path

from transformers import AutoTokenizer, AutoConfig
from peft import PeftModel
from models import CADRecode
from utils import inference_single_sample


def load_lora_model(base_model_path: str, lora_path: str, device: str = "auto"):
    """
    åŠ è½½LoRAæ¨¡å‹ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶ä¼˜å…ˆä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹
    
    Args:
        base_model_path: åŸºç¡€æ¨¡å‹è·¯å¾„
        lora_path: LoRAæƒé‡è·¯å¾„
        device: è®¾å¤‡
    
    Returns:
        model, tokenizer: åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨
    """
    lora_path = Path(lora_path)
    merged_model_path = lora_path / "merged_model"
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åˆå¹¶åçš„æ¨¡å‹
    if merged_model_path.exists() and (merged_model_path / "config.json").exists():
        print(f"ğŸ¯ Found merged model, loading from: {merged_model_path}")
        
        # åŠ è½½åˆ†è¯å™¨
        tokenizer = AutoTokenizer.from_pretrained(
            merged_model_path,
            pad_token='<|im_end|>',
            padding_side='left',
            trust_remote_code=True
        )
        
        # åŠ è½½åˆå¹¶åçš„æ¨¡å‹
        model_config = AutoConfig.from_pretrained(merged_model_path, trust_remote_code=True)
        if hasattr(model_config, 'sliding_window'):
            model_config.sliding_window = None
        
        model = CADRecode.from_pretrained(
            merged_model_path,
            config=model_config,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True
        )
        
        print(f"âœ… Merged model loaded successfully")
        
    else:
        print(f"ğŸ”§ No merged model found, loading LoRA adapter from: {lora_path}")
        print(f"Base model: {base_model_path}")
        
        # åŠ è½½åˆ†è¯å™¨
        tokenizer = AutoTokenizer.from_pretrained(
            base_model_path,
            pad_token='<|im_end|>',
            padding_side='left',
            trust_remote_code=True
        )
        
        # åŠ è½½æ¨¡å‹é…ç½®
        model_config = AutoConfig.from_pretrained(base_model_path, trust_remote_code=True)
        
        # ç¦ç”¨æ»‘åŠ¨çª—å£æ³¨æ„åŠ›
        if hasattr(model_config, 'sliding_window'):
            model_config.sliding_window = None
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        base_model = CADRecode.from_pretrained(
            base_model_path,
            config=model_config,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True
        )
        
        # åŠ è½½LoRAæƒé‡
        model = PeftModel.from_pretrained(base_model, lora_path)
        
        # åˆå¹¶æƒé‡ä»¥æé«˜æ¨ç†é€Ÿåº¦
        print("ğŸ”„ Merging LoRA weights for faster inference...")
        model = model.merge_and_unload()
        
        print(f"âœ… LoRA adapter loaded and merged successfully")
    
    # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    model.eval()
    
    return model, tokenizer


def load_point_cloud(file_path: str, num_points: int = 256) -> np.ndarray:
    """åŠ è½½ç‚¹äº‘æ–‡ä»¶"""
    if not Path(file_path).exists():
        raise FileNotFoundError(f"Point cloud file not found: {file_path}")
    
    # æ”¯æŒå¤šç§æ ¼å¼
    if file_path.endswith('.npy'):
        point_cloud = np.load(file_path)
    elif file_path.endswith('.txt'):
        point_cloud = np.loadtxt(file_path)
    else:
        raise ValueError(f"Unsupported file format: {file_path}")
    
    # ç¡®ä¿å½¢çŠ¶æ­£ç¡®
    if point_cloud.shape[1] != 3:
        raise ValueError(f"Point cloud should have 3 coordinates, got shape: {point_cloud.shape}")
    
    # è°ƒæ•´ç‚¹æ•°
    if point_cloud.shape[0] != num_points:
        if point_cloud.shape[0] > num_points:
            # éšæœºé‡‡æ ·
            indices = np.random.choice(point_cloud.shape[0], num_points, replace=False)
            point_cloud = point_cloud[indices]
        else:
            # é‡å¤é‡‡æ ·
            repeat_times = num_points // point_cloud.shape[0] + 1
            point_cloud = np.tile(point_cloud, (repeat_times, 1))[:num_points]
    
    return point_cloud.astype(np.float32)


def create_sample_point_cloud(shape: str = "cube", num_points: int = 256) -> np.ndarray:
    """åˆ›å»ºç¤ºä¾‹ç‚¹äº‘"""
    if shape == "cube":
        # åˆ›å»ºç«‹æ–¹ä½“ç‚¹äº‘
        points = []
        for i in range(num_points):
            x = np.random.uniform(-1, 1)
            y = np.random.uniform(-1, 1) 
            z = np.random.uniform(-1, 1)
            points.append([x, y, z])
        return np.array(points, dtype=np.float32)
    
    elif shape == "sphere":
        # åˆ›å»ºçƒä½“ç‚¹äº‘
        points = []
        for i in range(num_points):
            theta = np.random.uniform(0, 2*np.pi)
            phi = np.random.uniform(0, np.pi)
            r = np.random.uniform(0, 1)
            x = r * np.sin(phi) * np.cos(theta)
            y = r * np.sin(phi) * np.sin(theta)
            z = r * np.cos(phi)
            points.append([x, y, z])
        return np.array(points, dtype=np.float32)
    
    elif shape == "cylinder":
        # åˆ›å»ºåœ†æŸ±ä½“ç‚¹äº‘
        points = []
        for i in range(num_points):
            theta = np.random.uniform(0, 2*np.pi)
            r = np.random.uniform(0, 1)
            z = np.random.uniform(-1, 1)
            x = r * np.cos(theta)
            y = r * np.sin(theta)
            points.append([x, y, z])
        return np.array(points, dtype=np.float32)
    
    else:
        raise ValueError(f"Unknown shape: {shape}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="CAD-Recode LoRA Inference")
    parser.add_argument("--base_model", type=str, required=True, help="Base model path")
    parser.add_argument("--lora_path", type=str, required=True, help="LoRA weights path")
    parser.add_argument("--point_cloud_file", type=str, help="Point cloud file (.npy or .txt)")
    parser.add_argument("--shape", type=str, choices=["cube", "sphere", "cylinder"], 
                        default="cube", help="Generate sample point cloud shape")
    parser.add_argument("--num_points", type=int, default=256, help="Number of points")
    parser.add_argument("--max_new_tokens", type=int, default=768, help="Maximum tokens to generate")
    parser.add_argument("--device", type=str, default="auto", help="Device to use")
    parser.add_argument("--output", type=str, help="Output file to save generated code")
    
    args = parser.parse_args()
    
    # åŠ è½½æ¨¡å‹
    print("Loading LoRA model...")
    model, tokenizer = load_lora_model(args.base_model, args.lora_path, args.device)
    
    # åŠ è½½æˆ–åˆ›å»ºç‚¹äº‘
    if args.point_cloud_file:
        print(f"Loading point cloud from: {args.point_cloud_file}")
        point_cloud = load_point_cloud(args.point_cloud_file, args.num_points)
    else:
        print(f"Creating sample {args.shape} point cloud...")
        point_cloud = create_sample_point_cloud(args.shape, args.num_points)
    
    print(f"Point cloud shape: {point_cloud.shape}")
    
    # è¿›è¡Œæ¨ç†
    print("Generating CadQuery code...")
    generated_code = inference_single_sample(
        model, tokenizer, point_cloud, args.max_new_tokens
    )
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*50)
    print("Generated CadQuery Code:")
    print("="*50)
    print(generated_code)
    print("="*50)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(generated_code)
        print(f"\nCode saved to: {args.output}")
    
    # ç®€å•çš„ä»£ç éªŒè¯
    try:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„CadQueryè¯­æ³•
        if "cadquery" in generated_code.lower() or "cq." in generated_code:
            print("\nâœ… Generated code contains CadQuery syntax")
        else:
            print("\nâš ï¸  Generated code may not contain valid CadQuery syntax")
            
        # æ£€æŸ¥è¯­æ³•é”™è¯¯
        compile(generated_code, '<string>', 'exec')
        print("âœ… Generated code is syntactically valid Python")
        
    except SyntaxError as e:
        print(f"\nâŒ Syntax error in generated code: {e}")
    except Exception as e:
        print(f"\nâš ï¸  Could not validate code: {e}")


if __name__ == "__main__":
    main()
